open corebase
open corecuda
open tensorm

nominal gemm_config m_frag n_frag k_frag frag_in tile warp_size = {m_frag : int; n_frag : int; k_frag : int; tile : int; warp_size : int}
inl gemm_config forall m_frag n_frag k_frag frag_in tile warp_size. : gemm_config m_frag n_frag k_frag frag_in tile warp_size= gemm_config {
    m_frag = real real_core.type_lit_to_lit `m_frag
    n_frag = real real_core.type_lit_to_lit `n_frag
    k_frag = real real_core.type_lit_to_lit `k_frag
    tile = real real_core.type_lit_to_lit `tile
    warp_size = real real_core.type_lit_to_lit `warp_size
    }

inl wmma_gemm_shared forall m_frag n_frag k_frag frag_in tile warp_size float {number}. 
        (gemm_config {m_frag n_frag k_frag tile warp_size} : gemm_config m_frag n_frag k_frag frag_in tile warp_size)
        (alpha : float) (a,ta : tensor (int * int) float * bool) (b,tb : tensor (int * int) float * bool) 
        (beta : float) (c : tensor (int * int) float) =
    inl _ =
        inl swap (a,b) x = if x then b,a else a,b
        inl a_dim = swap a.dim ta
        inl b_dim = swap b.dim tb
        inl c_dim = c.dim
        assert (snd a_dim = fst b_dim) "The K dimension of the A and B tensors must match."
        assert (fst a_dim = fst c_dim) "The M dimension of the A and C tensors must match."
        assert (snd b_dim = snd c_dim) "The N dimension of the B and C tensors must match."

    inl a = 
        if ta then // col_major
            reshape (fun k,m => {k=k / tile}, {k_tile=tile}, {m=m / tile}, {m_tile=tile}) a
            |> reorder (fun k,{k_tile},m,{m_tile} => m,k,(k_tile,m_tile))
        else // row_major
            reshape (fun m,k => {m=m / tile}, {m_tile=tile}, {k=k / tile}, {k_tile=tile}) a
            |> reorder (fun m,{m_tile},k,{k_tile} => m,k,(m_tile,k_tile))
    inl b =
        if tb then // col_major
            reshape (fun n,k => {n=n / tile}, {n_tile=tile}, {k=k / tile}, {k_tile=tile}) b
            |> reorder (fun n,{n_tile},k,{k_tile} => n,k,(n_tile,k_tile))
        else // row_major
            reshape (fun k,n => {k=k / tile}, {k_tile=tile}, {n=n / tile}, {n_tile=tile}) b
            |> reorder (fun k,{k_tile},n,{n_tile} => n,k,(k_tile,n_tile))
    inl c = // row_major
        reshape (fun m,n => {m=m / tile}, {m_tile=tile}, {n=n / tile}, {n_tile=tile}) c
        |> reorder (fun m,{m_tile},n,{n_tile} => (m,n),(m_tile,n_tile))
    
    inl threads_per_block = 256
    inl blocks_per_grid = 24*(1576/threads_per_block)
    run blocks_per_grid threads_per_block (fun () =>
        global "#include <cublasdx.hpp>"
        global "using namespace cublasdx;"
        global "#include <cooperative_groups.h>"
        global "#include <cooperative_groups/memcpy_async.h>"
        global "using namespace cooperative_groups;"

        open cooperative_groups
        open tensorm.cuda

        inl block = create_block()
        inl memcpy_tile : _ (_ tile _) = create_thread_block_tile block
        
        loop_blocks_in_grid' (fst a.dim, fst b.dim) (fun m,n =>
            inl a = apply m a
            inl b = apply n b
            inl c = apply (m,n) c

            inl create_shared()  : tensor _ float = tensor_create_shared (tile, tile)
            
            inl c_shared' = create_shared()
            async_memcpy_tensor memcpy_tile {from=c; to=c_shared'}
            loop_linear' (fst a.dim) (fun k =>
                inl a = apply k a
                inl a_shared' = create_shared()
                sync block
                async_memcpy_tensor memcpy_tile {from=a; to=a_shared'} 

                inl b = apply k b
                inl b_shared' = create_shared()
                async_memcpy_tensor memcpy_tile {from=b; to=b_shared'} 
                wait memcpy_tile . sync block

                // NOTE: cuBLASDx expects inputs in column major layout
                inl b, ldb =  ptr_at_current_offset a_shared', stride_fst a_shared'
                inl a, lda =  ptr_at_current_offset b_shared', stride_fst b_shared'
                inl c, ldc =  ptr_at_current_offset c_shared', stride_fst c_shared'
                $"using size_desc = Size<!tile, !tile, !tile>"
                // $"using ld_desc = cublasdx::LeadingDimension<!lda, !ldb, !ldc>"
                $"using type_desc = Type<type::real>"
                $"using precision = Precision<`float>"
                inl tm ta : $"transpose_mode" = 
                    assert (lit_is ta) "The transpose modes should be literals."
                    if ta then $"constexpr auto v$ = transpose_mode::transposed" else $"constexpr auto v$ = transpose_mode::non_transposed"
                inl tm_b, tm_a = tm ta, tm tb
                $"using tm_desc = TransposeMode<!tm_a, !tm_b>"
                $"using sm = SM<890>"
                $"using BLAS = decltype(BlockDim<!threads_per_block>() + Block() + Function<function::MM>() + size_desc() + type_desc() + tm_desc() + precision() + sm())"
                inl a_size : int = $"BLAS::a_size"
                inl b_size : int = $"BLAS::b_size"
                inl c_size : int = $"BLAS::c_size"
                inl beta = if k = {k=0} then beta else 1
                $"BLAS().execute(!alpha, !a, !b, !beta, !c)"
                ()
                )
            sync block
            
            async_memcpy_tensor memcpy_tile {from=c_shared'; to=c}
            )
        )


inl main() =
    inl grid_range () : int = $"gridDim.x * blockDim.x"
    inl linear_id () : int = $"threadIdx.x + blockIdx.x * blockDim.x"

    inl get_body forall dim el. (x : tensor dim el) : array el = 
        real tensorm.utils.map (fun (tensor_body {array}) => array) x.bodies : array el

    inl random_normal dim =
        inl len : int = real open real_core in tensorm.utils.foldBack (*) dim 1
        inl t : array f32 = $"cp.random.normal(0,1,!len,cp.float32)" 
        fromArray t |> reshape (const dim)

    inl swap (a,b) x = if x then b,a else a,b
    inl cp_matmul (a : tensor (int * int) float * bool) (b : tensor (int * int) float * bool) (c : tensor (int * int) float) : tensor (int * int) float =
        inl transpose ta (x : array float) : array float = if ta then $"cp.transpose(!x)" else x
        inl f (ta : bool) (a_body : array float) (a_dim : int * int) : array float = 
            inl x : array float = $"!a_body.reshape(!a_dim)"
            transpose ta x
        inl g (a,ta : tensor (int * int) float * bool) = f ta (get_body a) a.dim
        inl a_body,b_body,c_body : array float * array float * array float = g a, g b, f false (get_body c) c.dim
        
        $"(cp.matmul(!a_body,!b_body)).flatten()"
        |> fromArray |> reshape (const c.dim)

    inl m,n,k : int * int * int = 512, 512, 512
    inl ta,tb = false, true
    inl [a; b; c] = listm.map random_normal ([swap (m, k) ta; swap (k, n) tb; m, n])
    inl average (nearTo : int) body = loop.for {from=0; nearTo} (fun (i : int) s => body i + s) 0 / (conv nearTo)
    global "from max_blocks_per_sm import max_blocks_per_sm"
    $"max_blocks_per_sm(cp.cuda.Device(),raw_module.get_function('entry0'),256,is_print=True)" : ()
    average 100 fun i =>
        inl d = cp_matmul (a,ta) (b,tb) c
        wmma_gemm_shared (gemm_config : gemm_config 16 16 8 wmma.tf32 32 32) 1 (a, ta) (b, tb) 0 c
        inl d,c = get_body d, get_body c
        $"cp.max(cp.abs(!c-!d))" : f32