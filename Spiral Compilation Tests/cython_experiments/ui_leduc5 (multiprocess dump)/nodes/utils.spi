union observation o a = Observation: o | Action: a
nominal player s o a = { prob : log_prob; observations : list (observation o a); state : s }
inl init' state = player {state prob=log_probm.from 1; observations=Nil} |> dyn
inl init forall observation action. : player () observation action = init' ()
nominal player_funs game_state s obs act r = {
    action : {game_state : game_state; id : u8; player : player s obs act;  player' : log_prob; chance_prob : log_prob; actions : a u64 act; next : (log_prob * act) * s -> r} -> r
    terminal : {game_state : game_state; id : u8; player : player s obs act; chance_prob : log_prob; reward : r2} -> ()
    }
type pl2 s1 s2 o a = log_prob * player s1 o a * player s2 o a

inl prob (player {prob}) = prob
inl state (player {state}) = state
inl observations (player {observations}) = observations
inl apply_action (player x) a = player {x with observations#=(::) (Action: a)}
inl apply_observation (player x) o = player {x with observations#=(::) (Observation: o)}
inl apply_changes (player x) ((prob,a),state) = player {x with state observations#=(::) (Action: a); prob#=log_probm.add prob}

inl sample_players_update pid (prob,x) (chance_prob,p1,p2) =
    log_probm.add prob chance_prob, 
    match pid with
    | Some: pid =>
        let update pid' p = if pid = pid' then apply_observation p x else p
        update 0 p1, update 1 p2
    | None =>
        inl update p = apply_observation p x 
        update p1, update p2

// Indexes randomly into an uniform categorical distrbution, weighting the choice by its probability.
inl choice one pid dist = one (sampling.randomInLength dist) pid dist