inl sample i pid dist f p =
    let f a b = f a b
    inl x = index dist i
    inl p = sample_players_update pid (log_probm.from (1 / f64 (length dist)),x) p
    f x p

inl draw i pid dist f p =
    let f a b = f a b
    inl x = index dist i
    inl ar = am.removeAtIndex i dist
    inl p = sample_players_update pid (log_probm.from (1 / f64 (length dist)),x) p
    f (x,ar) p

// Iterates over the an uniform categorical distribution, summing up the rewards divided by the length.
inl iter one pid dist f p =
    let rec loop i s = 
        inl prob = 1 / f64 (length dist)
        if i < length dist then inl r = one i pid dist f p in loop (i+1) (s+.r)
        else s *. prob
    loop 0 (r2 0)

inl nodes_2p forall game_state s1 s2 o a. (player_funs fp1, player_funs fp2) 
        : game2p game_state o a (pl2 s1 s2 o a -> r2) = game2p {
    terminal = fun (s1,s2) r (chance_prob,p1,p2) =>
        fp1.terminal {chance_prob game_state=s1; id=0; player=p1; reward=r} . fp2.terminal {chance_prob game_state=s2; id=1; player=p2; reward=r}
        r
    action = fun s pid ar f (chance_prob,p1,p2) =>
        let f (a : a) (b : pl2 s1 s2 o a) : r2 = real real_core.unbox a (fun _ => f a b)
        if pid = 0 then fp1.action {chance_prob game_state=s; id=0; player=p1; player'=prob p2; actions=ar; next=fun ((_,a),_ as cs) => f a (chance_prob,apply_changes p1 cs,apply_action p2 a)}
        else fp2.action {chance_prob game_state=s; player=p2; id=1; player'=prob p1; actions=ar; next=fun ((_,a),_ as cs) => f a (chance_prob,apply_action p1 a,apply_changes p2 cs)}
    draw = iter draw
    sample = iter sample
    }