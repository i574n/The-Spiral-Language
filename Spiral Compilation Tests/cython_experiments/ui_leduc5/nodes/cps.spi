inl sample i pid dist f (p,ret) =
    inl x = index dist i
    inl p = sample_players_update pid (to_log_prob (1 / f64 (length dist)),x) p
    f x (p,ret)

inl draw i pid dist f (p,ret) =
    inl x = index dist i
    inl ar = am.removeAtIndex i dist
    inl p = sample_players_update pid (to_log_prob (1 / f64 (length dist)),x) p
    f (x,ar) (p,ret)

// Iterates over the an uniform categorical distribution, summing up the rewards divided by the length.
inl iter one pid dist f (p,ret) =
    let rec loop i s = 
        inl prob = 1 / f64 (length dist)
        if i < length dist then one i pid dist f (p,dyn fun r => loop (i+1) (s+r))
        else ret (prob * s)
    loop 0 0

inl nodes_2p forall game_state s1 s2 o a ret. (player_funs fp1, player_funs fp2) 
        : game2p game_state o a (pl2 s1 s2 o a * (f64 -> ret) -> ret) = game2p {
    terminal = fun (s1,s2) r ((p1,p2),ret) => 
        fp1.terminal {game_state=s1; player=p1; reward=r} . fp2.terminal {game_state=s2; player=p2; reward= -r}
        ret r
    action = fun s pid ar f ((p1,p2),ret) =>
        if pid = 0 then fp1.action {game_state=s; player=p1; player'=prob p2; actions=ar; next=fun ((_,a),_ as cs) => f a ((apply_changes p1 cs,apply_action p2 a),ret)}
        else fp2.action {game_state=s; player=p2; player'=prob p1; actions=ar; next=fun ((_,a),_ as cs) => f a ((apply_action p1 a,apply_changes p2 cs),ret)}
    draw = choice draw
    sample = choice sample
    }