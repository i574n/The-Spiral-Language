inl main () =
    !!!!Import("ui_replay")
    inl buffer : ra u64 obj = am.empty
    inl p1 = agent.neural.create_buffer (agent.neural.create_net()) fun x =>
        open leduc
        inl show_card = function
            | King => "[color=ff0000]K[/color]"
            | Queen => "[color=ff0000]Q[/color]"
            | Jack => "[color=ff0000]J[/color]"
        inl show_action = function
            | Fold => "F"
            | Call => "C"
            | Raise => "R"
        open nodes
        inl (player p) = x.player
        inl trace =
            inl trace : ra u64 _ = am.empty
            listm.iterBack ((function Observation: x => show_card x | Action: x => show_action x) >> rm.add trace) p.observations
            rm.join' "" trace
        inl op_card = x.game_state |> snd |> fst |> fun {card id pot} => show_card card
        inl trace = $"f'{!trace} (vs. {!op_card})'" : string
        inl reward = x.game_state |> fst |> fun {card id pot} => if id = 0 then x.reward else -(x.reward)
        inl pstr x = $"'{:.5f}'.format(!x)" : string
        inl reward = pstr (x.reward : f64)
        inl prob_self = pstr (exp_log_prob p.probSelf)
        inl prob_op = pstr (exp_log_prob x.player')
        inl actions =
            inl trace : ra u64 _ = am.empty
            am.iter (show_action >> rm.add trace) x.actions
            rm.join' "" trace
        rm.add buffer $"{'trace': !trace, 'reward': !reward, 'prob_self': !prob_self, 'prob_op': !prob_op, 'actions': !actions}"
    inl p2 = agent.uniform.createEnum()
    inl populate_call () = 
        leduc.game (nodes.nodes_2p (p1.funs, p2.funs)) (p1.init,p2.init) |> ignore
        buffer
    $"ui_replay.run(!populate_call)"
    ()