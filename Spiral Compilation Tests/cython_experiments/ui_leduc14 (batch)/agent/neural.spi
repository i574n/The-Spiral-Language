nominal schema present future actions = {
    policy : serialization.dense.array.pu present
    value : serialization.dense.array.pu (present * future)
    actions : serialization.sparse.int.pu actions
    }
open leduc
nominal leduc_policy_input = {pid : u64; pot : u64; seq : a u64 (card * a u64 action)}
nominal leduc_net = {policy : obj; schema : schema leduc_policy_input card action; value : obj}

let obs_to_array (l : list (observation card action)) : a u64 (card * a u64 action) =
    let rec action (c,l) = function
        | Cons: (Observation: x), x' => (c,listm.rev l |> listm.toArray) :: action (x,Nil) x'
        | Cons: (Action: x), x' => action (c,x :: l) x'
        | Nil => (c,listm.rev l |> listm.toArray) :: Nil
    match listm.rev l with
    | Cons: (Observation: x), x' => action (x,Nil) x' |> listm.toArray
    | _ => failwith "Expected a card."
    
inl create_small_leduc_net () =
    inl schema =
        inl policy, value =
            open serialization.dense.array
            inl card = alt {king=Unit; queen=Unit; jack=Unit} : pu card
            inl action = alt {fold=Unit; call=Unit; raise=Unit} : pu action
            // Max pot size is 13, and 0 is impossible for Leduc due to the antes. 
            // Here I am mapping the 1-13 to 0-12 range and back.
            inl pot = wrap ((+) -1,(+) 1) (int 13) 
            inl pid = int 2
            inl policy =
                wrap ((fun pid,pot,seq => leduc_policy_input {pid pot seq}),(fun (leduc_policy_input {pid pot seq}) => pid, pot, seq))
                    (pid ** pot ** array 2 (card ** array 4 action))
            policy, policy ** card
        schema { 
            policy value
            actions =
                open serialization.sparse.int
                alt {fold=Unit; call=Unit; raise=Unit} : pu action
            }

    open serialization
    inl c,b,a = dense.array.size schema.policy, 64u64, sparse.int.size schema.actions

    !!!!Import("nets")
    leduc_net {schema policy = $"nets.small(!c,!b,!a)" : obj; value = $"nets.small(!c,!b,!a)" : obj}

inl policy (epsilon : f64) (leduc_net {policy value schema}) l =
    !!!!Import("torch")
    !!!!Import("torch.distributions")
    
    inl len = length l
    inl policy_size = serialization.dense.array.size schema.policy
    inl value_size = serialization.dense.array.size schema.value
    inl actions_size = serialization.sparse.int.size schema.actions

    inl data_value : obj = $"torch.zeros(!len,!value_size)"
    l |> am.iteri fun b (player_state, (leduc_state (p1,p2,community_card)), pid, actions) =>
        inl seq = pl2_observations player_state pid |> obs_to_array
        inl pot = if pid = p1.id then p1.pot else p2.pot
        schema.value.pickle (leduc_policy_input {pid= $"!pid"; pot= $"!pot"; seq},if pid = p1.id then p2.card else p1.card) (0, $"!data_value[!b,:]")
    inl action_indices : a u64 (a u64 _) = l |> am.generic.map fun (_,_,_,actions) => am.map schema.actions.pickle actions
    inl policy_mask : obj = $"torch.full((!len,!actions_size),float('-inf'))"
    am.iteri (fun b => am.iter (fun a => $"!policy_mask[!b,!a] = 0")) action_indices
    inl policy_raw : obj = $"!policy_mask + !policy.forward(!data_value[:,!policy_size])"
    inl policy_probs : obj = $"torch.softmax(!policy_raw,dim=-1)"

    inl policy_probs_detached : obj = $"!policy_probs.detach()"
    inl e = epsilon * (1.0 / f64 (serialization.sparse.int.size schema.actions))
    inl sample_indices : a u64 _ = $"torch.distributions.Categorical(!e + (1.0 - !epsilon) * !policy_probs_detached).sample().numpy()"
    inl policy : a u64 f32 = $"torch.gather(!policy_probs_detached,1,!sample_indices.unsqueeze(-1)).squeeze(-1).numpy()"
    inl l : a _ _ =
        am.map2 (fun policy a =>
            inl policy = f64 policy
            inl sample : f64 = e + (1.0 - epsilon) * policy
            log_prob_from {policy sample}, schema.actions.unpickle a
            ) policy sample_indices
    l, fun (r : a u64 r2) =>
        inl value_raw : obj = $"!value.forward(!data_value)"
        // inl value : a u64 f32 = 
        r