// So much for giving up on deep RL. I guess I will be using it after all. With upside down RL being a flop, the only two challenges
// left are transformers and their unsupervised learning. I'll tackle transformer architectures for the first time in this project.

// Maybe, just maybe the transformers on their own will be enough to crack Holdem, but if that fails, I'll use a curriculum of 
// training the agents on River poker so they can learn to read hands and then setting them loose on the full game. That will
// definitely work, though it is not as elegant as doing it all end to end.

// Update(7/17/2021): The pre-canned transformer that I've imported from the x_transformer library works horrible. After some effort, 
// I managed to succeed in making my own architecture which works much better than the existing ones. I am quite pleased with how
// it came out. I pared down the encoder to the bare essentials, and then the improvements that I did were right on the mark.

// That having said, I had overly inflated expectations of what the transformers would be capable of. Testing them on Leduc and
// vs the Flop callbot shows that they perform as well as an MLP. I thought that maybe the transformer architecture would improve
// the ability to hand read, but that is not so. I can't expect this to work on full Holdem better than an MLP.

// I guess they are worth using since they make learning on sequential data easier.

// I am decently sure that I did nothing wrong in my use of x_transformers. I doubt there is a problem with the library either.
// Instead, the more likely explanation is that just like for regular MLPs, the architectures that work in SL are badly affected by
// the variance of RL. My own innovations are much more roboust. So there is some value to paving your own way.

// With this I am done with transformers. For getting the agent to work on full Holdem, I had some very good ideas in the past
// couple of days that will ensure that my next attempt will result in the absolute state of the art RL architecture.

// For reducing the variance there is just no other choice, but to reach for TD methods. It is clear to me now. Although VR MCCFR
// works in the tabular regime, the recursive and shared state of NNs requires a softer touch. For all I know, the semi-tabular
// updates that I've invented might obliviate the need for various kinds of hacks such as target nets. I am quite sure that
// what causes even linear nets to diverge (Baird's counter example) becomes inapplicable to the kinds of updates I am doing.

// It is worth trying out. What is really going to make the agent state of the art are my exploration ideas. I am going to combine
// the ideas from the SAU paper and the AGAC paper to crack open exploration on top of reducing variance.

// Update(7/19/2021): Did some more manual architecture search. At first my efforts made things worse. It turns out what I 
// stumbled on two days ago is quite good. The two heads love it when an ensemble of head inputs get fed to them instead of being 
// preprocessed by a feedforward layer. But it is unecessary to do an inf cube and then normed square in the model evaluate. I've 
// made a specialized `TopEncoder` just for the top layer which just does a normed square and then normalizes across the heads. It 
// does just a single query for efficiency.

// Increasing the number of heads past 2 ** 4 seems to make the training significantly slower. Given how fast the evaluation is,
// for some reason the backwards pass is where the friction lies. The heads are important for stability - the variance of training
// is significantly reduced when they are many, but the emb dimension can't be traded off for them. For Leduc, 2 ** 5 is good.
// Going to 2 ** 4 seems to introduce some instability.

// With the 2 ** 4 heads and 2 ** 5 emb, the stability of the training is as good as for an MLP. The training times are 2x worse
// though. I'll have to make a decision whether I want to go back to MLPs or stick with transformers. I'll stick with them for now,
// as it would take effort to bring back MLPs.

// At any rate, the architecture here is quite viable. As soon as the run I am doing now finishes I'll leave this project as it is.
// The details on my experiments can be found in the commit.

packages: |core2-
modules:
    types-
    conv-
    serialization/
        dense/
            array
        sparse/
            int
    utils-
    sampling
    nodes-
    train
    hand_scorer
    hu_holdem
    leduc
    agent/
        uniform
        holdem_callbot
        tabular
        neural_leduc
        neural_holdem
    create_args_leduc
    create_args_holdem