inl main () =
    inl d = dictm.empty
    inl game = leduc.game()
    inl mult = 2000i32
    loopw.for' (from: 0i32 nearTo: 20) fun i =>
        open agent.cfr_sample_learned_infoset
        !!!!Import("time")
        inl t = $"time.perf_counter()" : f64
        $"print('start training')"
        loopw.for' (from: 0i32 nearTo: 100 * mult) fun _ =>
            ignore <| train.run (policy_train d) (policy_cur d) game
            ignore <| train.run (policy_cur d) (policy_train d) game
        inl t' = $"time.perf_counter()" : f64
        inl q = t' - t
        $"print('done training -', !q)"

        inl d_test = dictm.empty
        loopw.for' (from: 0i32 nearTo: 500 * mult) fun _ =>
            ignore <| train.run (policy_train d_test) (policy_avg d) game
        inl num_iterations = 20 * mult
        inl r = 
            loopw.for (from: 0i32 nearTo: num_iterations) (fun _ r =>
                r +! train.run (policy_cur d_test) (policy_avg d) game
                ) (r2 0) /! (f64 num_iterations)
        $"print('summary -',!i,!r)"
